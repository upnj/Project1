[
  {
    "objectID": "Project1.html",
    "href": "Project1.html",
    "title": "Project1",
    "section": "",
    "text": "The Public Use Microdata Sample (PUMS) Census API (Application Programming Interface) is a collection of data files from the United States Census Bureau that provides access to data samples of the U.S. population and housing units. More specifically, these PUMS data sets cover the HUD’s (U.S. Department of Housing and Urban Development) largest rental assistance programs (Public Housing, Section 8, etc). This data is compiled from responses to the American Community Surveys (ACS). The PUMS is comprised of two files: one for person records and the other for housing unit records. It includes geographic and household information including, but not limited to: family type, household income, race, gender, etc. The PUMS’ data sets are valuable sources of information to policymakers and the researchers, as it can give some insight on how to better allocate resources and focus on helping those who need it the most.\nBy leveraging these data sets, we hope to not only grow our R skills, but to learn a little more about the world around us. For the first half, we’ll be working on building functions, both helper and main functions, that will help us examine, check, process, manipulate, and build our main function to query PUMS’ API. The second half of the project will build onto the first and delve into functions to that will summarize data and create visuals.\nFirst thing’s first, with every R project, we install and load in the necessary packaaes to help create functions to do what we need.\n\n\n# Loading packages\nlibrary(tidyverse)\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(tidycensus)\nlibrary(lubridate)\n\n\nNext, we are going to show how URL can interact with the PUMS’ API. Typically we’d start with a more bare URL when building a URL from scratch (more on that later), but I ended choosing this one because it provided a more visually appealing output as an example. After setting up the URL and making a GET, request to PUMS’ API (a request sent to a server asking an API to provide a service/information), we’ll take that raw data, and parse it into JSON. The initial_parse returns a tibble with the column names on the first row, so we extract those names and set them as the column names. Then we drop the first row and print a nice little tibble to get a glimpse of what information the example_url contains (take a look below!). Here we have a small tibble, 6x4, because we used the function head. These are the steps to querying APIs. So in short, we assign a URL, formulate the API request, send it, allow time to handle the response, and process the data.\n\n\n# Sample API call, transformed to tibble\nexample_url &lt;- \"https://api.census.gov/data/2022/acs/acs1/pums?get=SEX,PWGTP,MAR&SCHL=24\"\ninitial_response &lt;- GET(url = example_url)\ninitial_parse &lt;- fromJSON(rawToChar(initial_response$content))\ncol_names &lt;- (initial_parse[1,])\ncolnames(initial_parse) &lt;- col_names\ninitial_parse &lt;- initial_parse[-1,]\ninitial_parse &lt;- as_tibble(initial_parse)\nhead(initial_parse)\n\n# A tibble: 6 × 4\n  SEX   PWGTP MAR   SCHL \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 2     6     5     24   \n2 2     23    2     24   \n3 1     23    3     24   \n4 1     80    5     24   \n5 1     16    1     24   \n6 1     107   3     24   \n\n\n\nTo keep things simple and organized, below are all of the variables and their assigned values. Here we created vectors for each variable to reference later on.\n\n\n# Numeric variables\nnum_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWMNP\", \"PWGTP\")\n\n# Categorical variables\ncat_vars &lt;- c(\"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\")\n\n# Time variables\ntime_vars &lt;- c(\"JWAP\", \"JWDP\")\n\n# Geography variables\ngeo_vars &lt;- c(\"All\", \"Region\", \"Division\", \"State\")\n\n# Combined variables (numeric categorical, time)\ncombined_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWMNP\", \"PWGTP\", \"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\", \"JWAP\", \"JWDP\")\n\n\nNext we’ll dive into all of the functions we made in order to create our main API query. The first one we have is the year_checker function. Our if statement here only allows the function to pass if the year is between 2010 to 2022 (values are inclusive). However, if the year falls outside of the range, a stop function will raise an error message and cease execution of the code.\n\n\n# Year Checker\n# Function to check if entered year is valid\n\nyear_checker &lt;- function(year) {\n  if (year &gt; 2022 | year &lt; 2010) {\n    stop(\"Invalid year value. Please type in a number between 2010 and 2022.\")\n  }\n}\n\n\nOur second function, the num_checker, checks and coerces our assigned numeric and time variables to their respective data types. Due to the parsed JSON data, our data defaulted to a data type of character. Coercing the variables to the desired data type allows for meaning manipulation and analysis. This function contains 1 parameter and takes in 2 vectors, num_vars and time_vars, which is used to determine if the user input is of type num or time then converts it respectively to its desired data type. The function works by looping the column names from initial_parse. Each column name is checked to see if its name matches any from the 2 vectors, num_vars or time_vars. If the column name matches in num_vars, it will be converted to numeric through the use of as.numeric. Similarly with time_vars, it will be converted to a time format through the use of as.POSIXct. Once the function finishes looping, it will return the modified tibble/dataframe.\n\n\n# Numeric Checker\n# Function to convert columns to desired numeric data types\n\nnum_checker &lt;- function(initial_parse) {\n    num_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWMNP\", \"PWGTP\")\n    time_vars &lt;- c(\"JWAP\", \"JWDP\")\n    col_names &lt;- colnames(initial_parse) \n      for (name in col_names) {\n         if (name %in% num_vars) {\n            print(name)   \n            initial_parse[[name]] &lt;- as.numeric(initial_parse[[name]])\n            \n         }\n        if (name %in% time_vars) {\n            print(name)   \n            #initial_parse[[name]] &lt;- as.POSIXct(initial_parse[[name]], format = \"%H:%M\")\n            \n        }\n      }\n    return(initial_parse)\n}\n\n# Testing purposes/example\n# initial_parse &lt;- num_checker(initial_parse)\n\n\nOur time checker function works to change our time_vars into desired time data tpes.\n\n\n# Time Checker - NOT FINISHED\n# Function to convert columns to desired time data types\n# Currently NOT a function yet, but almost\n\n# JWAP - Example J. Post to use* remember to clean these\ntemp &lt;- httr::GET(\"https://api.census.gov/data/2022/acs/acs1/pums/variables/JWAP.json\")\n#turn it into a list\ntemp_list &lt;- temp$content |&gt; rawToChar() |&gt;jsonlite::fromJSON()\n#grab just the names of JWAP and their values\nJWAP &lt;- temp_list$values$item\n#reorder just so it is clearer\nJWAP_values &lt;- JWAP[sort(names(JWAP))]\n\n\ncount = 1\nfor (a in JWAP_values){\n    if(a!=\"N/A (not a worker; worker who worked from home)\"){\n        time_list = list()\n        time_split &lt;- strsplit(a, \" to \")\n        for (i in time_split[[1]]) {\n          #print(i)\n          i &lt;- gsub(\"\\\\.\",'',i)\n          i &lt;- gsub(\" \",'', i)\n          date_time &lt;- strptime(i, format = \"%I:%M%p\")\n          sec_since_mn &lt;- as.numeric(difftime(date_time, as.POSIXct(\"00:00\", format = \"%H:%M\"), units = \"secs\"))\n          time_list &lt;- append(time_list, sec_since_mn)\n        }\n          JWAP_values[[count]] &lt;- (time_list[[1]] + time_list[[2]]) / 2\n          avg_time&lt;- (time_list[[1]] + time_list[[2]]) / 2\n          avg_time2 &lt;- as.POSIXct(avg_time, origin = \"1970-01-01\", tz = \"UTC\")\n          JWAP_values[[count]] &lt;- strftime(avg_time2, format = \"%I:%M%p\")\n          \n    }\n\n  else JWAP_values[[count]] &lt;- a\n  count = count + 1\n}\n\n\n\n\n\n# JWDP - Example J. Post to use* remember to clean these\ntemp &lt;- httr::GET(\"https://api.census.gov/data/2022/acs/acs1/pums/variables/JWDP.json\")\n#turn it into a list\ntemp_list &lt;- temp$content |&gt; rawToChar() |&gt;jsonlite::fromJSON()\n#grab just the names of JWDP and their values\nJWDP &lt;- temp_list$values$item\n#reorder just so it is clearer\nJWDP_values &lt;- JWDP[sort(names(JWDP))]\n\n\ncount = 1\nfor (a in JWDP_values){\n    if(a!=\"N/A (not a worker; worker who worked from home)\"){\n        time_list = list()\n        time_split &lt;- strsplit(a, \" to \")\n        for (i in time_split[[1]]) {\n          #print(i)\n          i &lt;- gsub(\"\\\\.\",'',i)\n          i &lt;- gsub(\" \",'', i)\n          date_time &lt;- strptime(i, format = \"%I:%M%p\")\n          sec_since_mn &lt;- as.numeric(difftime(date_time, as.POSIXct(\"00:00\", format = \"%H:%M\"), units = \"secs\"))\n          time_list &lt;- append(time_list, sec_since_mn)\n        }\n          JWDP_values[[count]] &lt;- (time_list[[1]] + time_list[[2]]) / 2\n          avg_time&lt;- (time_list[[1]] + time_list[[2]]) / 2\n          avg_time2 &lt;- as.POSIXct(avg_time, origin = \"1970-01-01\", tz = \"UTC\")\n          JWDP_values[[count]] &lt;- strftime(avg_time2, format = \"%I:%M%p\")\n          \n    }\n\n  else JWDP_values[[count]] &lt;- a\n  count = count + 1\n}\n\n\nCategorical checker works similarly to the numeric checker. This function contains 1 parameter and takes in 1 vector, which is used to determine if the user input is of type factor then converts it respectively to its desired data type.\n\n\n# Categorical checker\n# Function to convert columns to desired factor data types\n\ncat_checker &lt;- function(initial_parse) {\n    cat_vars &lt;- c(\"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\")\n    col_names &lt;- colnames(initial_parse) \n      for (name in col_names) {\n         if (name %in% cat_vars) {\n            print(name)   \n            initial_parse[[name]] &lt;- as.factor(initial_parse[[name]])\n    }\n      }\n    initial_parse &lt;- initial_parse %&gt;%\n      mutate(\n        SEX = recode(SEX, \"1\" = \"Male\", \"2\" = \"Female\"))\n      return(initial_parse)\n}\n\n# Testing purposes/example\n# cat_checker(initial_parse)\n\n\nNext we have the geography checker. This function has 1 parameter and takes in 1 vector. If the provided geography_level is in the geo_vars vector, it will print that the geography level is valid. If not then it will print is not valid.\n\n\n# Geography Checker\n# Function to specify and  check if geography level is correct\n\ngeo_checker &lt;- function(geography_level, geography_subset) {\n  geo_vars &lt;- c(\"All\", \"Region\", \"Division\", \"State\")\n  if (geography_level %in% geo_vars) {\n    print(\"Geography level is valid.\") \n  }\n  else {\n    print(\"Geography level is not valid.\")\n  }\n}\n\n\n# Testing purposes/example\n# geo_checker(\"State\", \"08\")\n\n\nHere we have a function to query the census. This function contains 4 parameters. First, an empty tibble is initialized in order to store the results; this is important as it holds the multiple tibbles to later bind together. We assign a variable named year_list to take on the function string split for parameter, year, because we want to allow the user to be able to specify multiple years of survey data. String split works here because when inputting multiple years, “2012,2013,2015”, the user needs to input the years all as one string, then strsplit will work to split the different years into a list of year to call each year separately. The for loop at the bottom, (i in year_list[[1]]), loops over the list of years from the user into the query_url, allowing them to make API requests for each given year.\nNext, there are some words that we hard coded into the URL because we needed to return those columns, we chose: “PWGTP”, “GASP”, and “FER”. However, if the user doesn’t know, they could input one of these columns again, producing a duplicate column. To fix this, we have to use grepl, to search for a string within a string then we use gsub to remove the said string. The second gsub is a catch all, removing commas from before/after the string due to user input. This way, even if the user inputs those columns, it would no longer create a duplicate. Then we create an if statement where it does not allow the user to input a geography_subset if they choose “All” by creating a variable named geo_meta and add it onto our query_url below. So to briefly go over our first example, bottom portion of the code is using the given query_url, we send a GET request to formulate the API request, allow time to handle the response, process the data, extract column nam, apply them accordingly, then create tibbles. As mentioned earlier, if user inputs multiple years then the for loop won’t end until the last inputted year, then the bind_rows function will combine all of the tibbles from each year of the user input together.\n\n\n# Function to Query the Census API \n# Created if statements using grepl/gsub to remove duplicate columns\n# Allow users to call multiple years then combining tibbles as the end using bind_rowss\n# Used helper GET here then turned into tibble\n\ncensus_query &lt;- function(year, geography_level, geography_subset, get) {\n    initial_parse_final &lt;- tibble()\n    year_list &lt;- strsplit(year, \",\")\n    url &lt;- \"https://api.census.gov/data/\"\n    if (grepl(\"PWGTP\", get)) {\n      get &lt;- gsub(\"PWGTP|PWGTP,\",'',get) # to remove actual value or the comma after\n      get &lt;- gsub(\"^\\\\,|\\\\,$\",'',get) # catch all, if there's a comma before/after of user input\n    }\n    if (grepl(\"GASP\", get)) {\n      get &lt;- gsub(\"GASP|GASP,\",'',get)\n      get &lt;- gsub(\"^\\\\,|\\\\,$\",'',get)\n    }\n    if (grepl(\"FER\", get)) {\n      get &lt;- gsub(\"FER|FER,\",'',get)\n      get &lt;- gsub(\"^\\\\,|\\\\,$\",'',get)\n    }\n    geo_meta &lt;- paste0(\"&for=\", geography_level,\":\",geography_subset)\n    if (geography_level == \"All\") {\n      geo_meta &lt;- \"\"\n    }\n    for (i in year_list[[1]]) {\n      query_url &lt;- paste0(url,i,\"/acs/acs1/pums?\",\"get=PWGTP,GASP,FER,\",get,geo_meta)\n      initial_response &lt;- GET(url = query_url)\n      initial_parse &lt;- fromJSON(rawToChar(initial_response$content))\n      col_names &lt;- (initial_parse[1,])\n      colnames(initial_parse) &lt;- col_names\n      initial_parse &lt;- initial_parse[-1,]\n      initial_parse &lt;- as_tibble(initial_parse)\n      initial_parse_final &lt;- bind_rows(initial_parse,initial_parse_final)\n    }\n    return(initial_parse_final)\n}\n\n\n# Testing purposes/example\n# initial_parse &lt;- census_query(year = \"2011,2014\", \"State\", \"08\", \"AGEP,SEX\")\n\n\nNow we can create our final/main API query. This API query contains 4 parameters (year = “2022”, geography_level = “All”, geography_subset and get = “SEX,AGEP,PWGTP”, with their respective defaults) and takes in vector combined_vars. We create a strsplit for the get results, similarly to what we did for the years in the census_query results. When a user inputs variables, it will check and ensure those column names are valid. If they are then it will print, “Column X entered is valid” and if not then it will tell the user to try again. After that, initial_parse is reassigned and overwritten once it goes through each function (census_query, num_checker, time_checker, cat_checker) and checker (geo_checker, year_checker). Then will return a final tibble at the end.\n\n\n# Main API Query Function\n# Added combined_vars and for loop to validate and check inputted columns are valid\n\nmain_query &lt;- function(year = \"2022\", \n                       geography_level = \"All\", \n                       geography_subset,  \n                       get = \"SEX,AGEP,PWGTP\") {\n    combined_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWMNP\", \"PWGTP\", \"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\", \"JWAP\", \"JWDP\")\n    get_list &lt;- strsplit(get, \",\")\n    for (i in get_list[[1]]) {\n      if (i %in% combined_vars) {\n        cat(\"Column (\",i ,\") entered is valid.\")\n      }\n      else (\n        stop(\"Column (\",i,\") entered is not valid. Try again\")\n            )\n    }\n    initial_parse &lt;- census_query(year, geography_level, geography_subset, get)\n    initial_parse &lt;- num_checker(initial_parse)\n    initial_parse &lt;- cat_checker(initial_parse)\n    geo_checker(geography_level, geography_subset)\n    year_checker(year) \n    return(initial_parse)\n} \n\n# Testing purposes/example\n# test &lt;- main_query(\"2018,2015\", \"State\", \"08\", \"FER,JWAP,SEX,SCHL,GASP\")\n \n# All variable query\neverything &lt;- main_query(\"2022\", \"State\", \"08\", \"AGEP,GASP,GRPIP,JWMNP,PWGTP,FER,HHL,HISPEED,JWTRNS,SCH,SCHL,SEX,JWAP,JWDP\")\n\nColumn ( AGEP ) entered is valid.Column ( GASP ) entered is valid.Column ( GRPIP ) entered is valid.Column ( JWMNP ) entered is valid.Column ( PWGTP ) entered is valid.Column ( FER ) entered is valid.Column ( HHL ) entered is valid.Column ( HISPEED ) entered is valid.Column ( JWTRNS ) entered is valid.Column ( SCH ) entered is valid.Column ( SCHL ) entered is valid.Column ( SEX ) entered is valid.Column ( JWAP ) entered is valid.Column ( JWDP ) entered is valid.[1] \"PWGTP\"\n[1] \"GASP\"\n[1] \"AGEP\"\n[1] \"GRPIP\"\n[1] \"JWMNP\"\n[1] \"JWAP\"\n[1] \"JWDP\"\n[1] \"FER\"\n[1] \"HHL\"\n[1] \"HISPEED\"\n[1] \"JWTRNS\"\n[1] \"SCH\"\n[1] \"SCHL\"\n[1] \"SEX\"\n[1] \"Geography level is valid.\"\n\nprint(everything)\n\n# A tibble: 59,841 × 15\n   PWGTP  GASP FER    AGEP GRPIP JWMNP HHL   HISPEED JWTRNS SCH   SCHL  SEX   \n   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;   &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; \n 1    70     3 2        18     0     0 0     0       11     2     18    Female\n 2    41     3 0        35     0     0 0     0       0      1     14    Male  \n 3    35     3 0        40     0     0 0     0       0      1     13    Male  \n 4    30     3 2        20     0     0 0     0       0      2     19    Female\n 5     4     3 0        14     0     0 0     0       0      2     11    Male  \n 6    75     3 2        28     0     0 0     0       0      1     16    Female\n 7    22     3 0        47     0     0 0     0       0      1     16    Male  \n 8    36     3 0        28     0     0 0     0       0      1     16    Male  \n 9    59     3 0        77     0     0 0     0       0      1     16    Female\n10    11     3 0        20     0     2 0     0       10     1     18    Male  \n# ℹ 59,831 more rows\n# ℹ 3 more variables: JWAP &lt;chr&gt;, JWDP &lt;chr&gt;, state &lt;chr&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section we have created 2 functions “Summary” function takes the data from tibble and generate summary statistics (mean and standard deviation) for all numeric variables and counts for all categorical variables from the data frame. This function takes three arguments - class census, numeric variables to generate summary statistics and categorical variables.\n\n\n\n\n\ntest this"
  },
  {
    "objectID": "Project1.html#introduction",
    "href": "Project1.html#introduction",
    "title": "Project1",
    "section": "",
    "text": "The Public Use Microdata Sample (PUMS) Census API (Application Programming Interface) is a collection of data files from the United States Census Bureau that provides access to data samples of the U.S. population and housing units. More specifically, these PUMS data sets cover the HUD’s (U.S. Department of Housing and Urban Development) largest rental assistance programs (Public Housing, Section 8, etc). This data is compiled from responses to the American Community Surveys (ACS). The PUMS is comprised of two files: one for person records and the other for housing unit records. It includes geographic and household information including, but not limited to: family type, household income, race, gender, etc. The PUMS’ data sets are valuable sources of information to policymakers and the researchers, as it can give some insight on how to better allocate resources and focus on helping those who need it the most.\nBy leveraging these data sets, we hope to not only grow our R skills, but to learn a little more about the world around us. For the first half, we’ll be working on building functions, both helper and main functions, that will help us examine, check, process, manipulate, and build our main function to query PUMS’ API. The second half of the project will build onto the first and delve into functions to that will summarize data and create visuals.\nFirst thing’s first, with every R project, we install and load in the necessary packaaes to help create functions to do what we need.\n\n\n# Loading packages\nlibrary(tidyverse)\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(tidycensus)\nlibrary(lubridate)\n\n\nNext, we are going to show how URL can interact with the PUMS’ API. Typically we’d start with a more bare URL when building a URL from scratch (more on that later), but I ended choosing this one because it provided a more visually appealing output as an example. After setting up the URL and making a GET, request to PUMS’ API (a request sent to a server asking an API to provide a service/information), we’ll take that raw data, and parse it into JSON. The initial_parse returns a tibble with the column names on the first row, so we extract those names and set them as the column names. Then we drop the first row and print a nice little tibble to get a glimpse of what information the example_url contains (take a look below!). Here we have a small tibble, 6x4, because we used the function head. These are the steps to querying APIs. So in short, we assign a URL, formulate the API request, send it, allow time to handle the response, and process the data.\n\n\n# Sample API call, transformed to tibble\nexample_url &lt;- \"https://api.census.gov/data/2022/acs/acs1/pums?get=SEX,PWGTP,MAR&SCHL=24\"\ninitial_response &lt;- GET(url = example_url)\ninitial_parse &lt;- fromJSON(rawToChar(initial_response$content))\ncol_names &lt;- (initial_parse[1,])\ncolnames(initial_parse) &lt;- col_names\ninitial_parse &lt;- initial_parse[-1,]\ninitial_parse &lt;- as_tibble(initial_parse)\nhead(initial_parse)\n\n# A tibble: 6 × 4\n  SEX   PWGTP MAR   SCHL \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 2     6     5     24   \n2 2     23    2     24   \n3 1     23    3     24   \n4 1     80    5     24   \n5 1     16    1     24   \n6 1     107   3     24   \n\n\n\nTo keep things simple and organized, below are all of the variables and their assigned values. Here we created vectors for each variable to reference later on.\n\n\n# Numeric variables\nnum_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWMNP\", \"PWGTP\")\n\n# Categorical variables\ncat_vars &lt;- c(\"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\")\n\n# Time variables\ntime_vars &lt;- c(\"JWAP\", \"JWDP\")\n\n# Geography variables\ngeo_vars &lt;- c(\"All\", \"Region\", \"Division\", \"State\")\n\n# Combined variables (numeric categorical, time)\ncombined_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWMNP\", \"PWGTP\", \"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\", \"JWAP\", \"JWDP\")\n\n\nNext we’ll dive into all of the functions we made in order to create our main API query. The first one we have is the year_checker function. Our if statement here only allows the function to pass if the year is between 2010 to 2022 (values are inclusive). However, if the year falls outside of the range, a stop function will raise an error message and cease execution of the code.\n\n\n# Year Checker\n# Function to check if entered year is valid\n\nyear_checker &lt;- function(year) {\n  if (year &gt; 2022 | year &lt; 2010) {\n    stop(\"Invalid year value. Please type in a number between 2010 and 2022.\")\n  }\n}\n\n\nOur second function, the num_checker, checks and coerces our assigned numeric and time variables to their respective data types. Due to the parsed JSON data, our data defaulted to a data type of character. Coercing the variables to the desired data type allows for meaning manipulation and analysis. This function contains 1 parameter and takes in 2 vectors, num_vars and time_vars, which is used to determine if the user input is of type num or time then converts it respectively to its desired data type. The function works by looping the column names from initial_parse. Each column name is checked to see if its name matches any from the 2 vectors, num_vars or time_vars. If the column name matches in num_vars, it will be converted to numeric through the use of as.numeric. Similarly with time_vars, it will be converted to a time format through the use of as.POSIXct. Once the function finishes looping, it will return the modified tibble/dataframe.\n\n\n# Numeric Checker\n# Function to convert columns to desired numeric data types\n\nnum_checker &lt;- function(initial_parse) {\n    num_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWMNP\", \"PWGTP\")\n    time_vars &lt;- c(\"JWAP\", \"JWDP\")\n    col_names &lt;- colnames(initial_parse) \n      for (name in col_names) {\n         if (name %in% num_vars) {\n            print(name)   \n            initial_parse[[name]] &lt;- as.numeric(initial_parse[[name]])\n            \n         }\n        if (name %in% time_vars) {\n            print(name)   \n            #initial_parse[[name]] &lt;- as.POSIXct(initial_parse[[name]], format = \"%H:%M\")\n            \n        }\n      }\n    return(initial_parse)\n}\n\n# Testing purposes/example\n# initial_parse &lt;- num_checker(initial_parse)\n\n\nOur time checker function works to change our time_vars into desired time data tpes.\n\n\n# Time Checker - NOT FINISHED\n# Function to convert columns to desired time data types\n# Currently NOT a function yet, but almost\n\n# JWAP - Example J. Post to use* remember to clean these\ntemp &lt;- httr::GET(\"https://api.census.gov/data/2022/acs/acs1/pums/variables/JWAP.json\")\n#turn it into a list\ntemp_list &lt;- temp$content |&gt; rawToChar() |&gt;jsonlite::fromJSON()\n#grab just the names of JWAP and their values\nJWAP &lt;- temp_list$values$item\n#reorder just so it is clearer\nJWAP_values &lt;- JWAP[sort(names(JWAP))]\n\n\ncount = 1\nfor (a in JWAP_values){\n    if(a!=\"N/A (not a worker; worker who worked from home)\"){\n        time_list = list()\n        time_split &lt;- strsplit(a, \" to \")\n        for (i in time_split[[1]]) {\n          #print(i)\n          i &lt;- gsub(\"\\\\.\",'',i)\n          i &lt;- gsub(\" \",'', i)\n          date_time &lt;- strptime(i, format = \"%I:%M%p\")\n          sec_since_mn &lt;- as.numeric(difftime(date_time, as.POSIXct(\"00:00\", format = \"%H:%M\"), units = \"secs\"))\n          time_list &lt;- append(time_list, sec_since_mn)\n        }\n          JWAP_values[[count]] &lt;- (time_list[[1]] + time_list[[2]]) / 2\n          avg_time&lt;- (time_list[[1]] + time_list[[2]]) / 2\n          avg_time2 &lt;- as.POSIXct(avg_time, origin = \"1970-01-01\", tz = \"UTC\")\n          JWAP_values[[count]] &lt;- strftime(avg_time2, format = \"%I:%M%p\")\n          \n    }\n\n  else JWAP_values[[count]] &lt;- a\n  count = count + 1\n}\n\n\n\n\n\n# JWDP - Example J. Post to use* remember to clean these\ntemp &lt;- httr::GET(\"https://api.census.gov/data/2022/acs/acs1/pums/variables/JWDP.json\")\n#turn it into a list\ntemp_list &lt;- temp$content |&gt; rawToChar() |&gt;jsonlite::fromJSON()\n#grab just the names of JWDP and their values\nJWDP &lt;- temp_list$values$item\n#reorder just so it is clearer\nJWDP_values &lt;- JWDP[sort(names(JWDP))]\n\n\ncount = 1\nfor (a in JWDP_values){\n    if(a!=\"N/A (not a worker; worker who worked from home)\"){\n        time_list = list()\n        time_split &lt;- strsplit(a, \" to \")\n        for (i in time_split[[1]]) {\n          #print(i)\n          i &lt;- gsub(\"\\\\.\",'',i)\n          i &lt;- gsub(\" \",'', i)\n          date_time &lt;- strptime(i, format = \"%I:%M%p\")\n          sec_since_mn &lt;- as.numeric(difftime(date_time, as.POSIXct(\"00:00\", format = \"%H:%M\"), units = \"secs\"))\n          time_list &lt;- append(time_list, sec_since_mn)\n        }\n          JWDP_values[[count]] &lt;- (time_list[[1]] + time_list[[2]]) / 2\n          avg_time&lt;- (time_list[[1]] + time_list[[2]]) / 2\n          avg_time2 &lt;- as.POSIXct(avg_time, origin = \"1970-01-01\", tz = \"UTC\")\n          JWDP_values[[count]] &lt;- strftime(avg_time2, format = \"%I:%M%p\")\n          \n    }\n\n  else JWDP_values[[count]] &lt;- a\n  count = count + 1\n}\n\n\nCategorical checker works similarly to the numeric checker. This function contains 1 parameter and takes in 1 vector, which is used to determine if the user input is of type factor then converts it respectively to its desired data type.\n\n\n# Categorical checker\n# Function to convert columns to desired factor data types\n\ncat_checker &lt;- function(initial_parse) {\n    cat_vars &lt;- c(\"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\")\n    col_names &lt;- colnames(initial_parse) \n      for (name in col_names) {\n         if (name %in% cat_vars) {\n            print(name)   \n            initial_parse[[name]] &lt;- as.factor(initial_parse[[name]])\n    }\n      }\n    initial_parse &lt;- initial_parse %&gt;%\n      mutate(\n        SEX = recode(SEX, \"1\" = \"Male\", \"2\" = \"Female\"))\n      return(initial_parse)\n}\n\n# Testing purposes/example\n# cat_checker(initial_parse)\n\n\nNext we have the geography checker. This function has 1 parameter and takes in 1 vector. If the provided geography_level is in the geo_vars vector, it will print that the geography level is valid. If not then it will print is not valid.\n\n\n# Geography Checker\n# Function to specify and  check if geography level is correct\n\ngeo_checker &lt;- function(geography_level, geography_subset) {\n  geo_vars &lt;- c(\"All\", \"Region\", \"Division\", \"State\")\n  if (geography_level %in% geo_vars) {\n    print(\"Geography level is valid.\") \n  }\n  else {\n    print(\"Geography level is not valid.\")\n  }\n}\n\n\n# Testing purposes/example\n# geo_checker(\"State\", \"08\")\n\n\nHere we have a function to query the census. This function contains 4 parameters. First, an empty tibble is initialized in order to store the results; this is important as it holds the multiple tibbles to later bind together. We assign a variable named year_list to take on the function string split for parameter, year, because we want to allow the user to be able to specify multiple years of survey data. String split works here because when inputting multiple years, “2012,2013,2015”, the user needs to input the years all as one string, then strsplit will work to split the different years into a list of year to call each year separately. The for loop at the bottom, (i in year_list[[1]]), loops over the list of years from the user into the query_url, allowing them to make API requests for each given year.\nNext, there are some words that we hard coded into the URL because we needed to return those columns, we chose: “PWGTP”, “GASP”, and “FER”. However, if the user doesn’t know, they could input one of these columns again, producing a duplicate column. To fix this, we have to use grepl, to search for a string within a string then we use gsub to remove the said string. The second gsub is a catch all, removing commas from before/after the string due to user input. This way, even if the user inputs those columns, it would no longer create a duplicate. Then we create an if statement where it does not allow the user to input a geography_subset if they choose “All” by creating a variable named geo_meta and add it onto our query_url below. So to briefly go over our first example, bottom portion of the code is using the given query_url, we send a GET request to formulate the API request, allow time to handle the response, process the data, extract column nam, apply them accordingly, then create tibbles. As mentioned earlier, if user inputs multiple years then the for loop won’t end until the last inputted year, then the bind_rows function will combine all of the tibbles from each year of the user input together.\n\n\n# Function to Query the Census API \n# Created if statements using grepl/gsub to remove duplicate columns\n# Allow users to call multiple years then combining tibbles as the end using bind_rowss\n# Used helper GET here then turned into tibble\n\ncensus_query &lt;- function(year, geography_level, geography_subset, get) {\n    initial_parse_final &lt;- tibble()\n    year_list &lt;- strsplit(year, \",\")\n    url &lt;- \"https://api.census.gov/data/\"\n    if (grepl(\"PWGTP\", get)) {\n      get &lt;- gsub(\"PWGTP|PWGTP,\",'',get) # to remove actual value or the comma after\n      get &lt;- gsub(\"^\\\\,|\\\\,$\",'',get) # catch all, if there's a comma before/after of user input\n    }\n    if (grepl(\"GASP\", get)) {\n      get &lt;- gsub(\"GASP|GASP,\",'',get)\n      get &lt;- gsub(\"^\\\\,|\\\\,$\",'',get)\n    }\n    if (grepl(\"FER\", get)) {\n      get &lt;- gsub(\"FER|FER,\",'',get)\n      get &lt;- gsub(\"^\\\\,|\\\\,$\",'',get)\n    }\n    geo_meta &lt;- paste0(\"&for=\", geography_level,\":\",geography_subset)\n    if (geography_level == \"All\") {\n      geo_meta &lt;- \"\"\n    }\n    for (i in year_list[[1]]) {\n      query_url &lt;- paste0(url,i,\"/acs/acs1/pums?\",\"get=PWGTP,GASP,FER,\",get,geo_meta)\n      initial_response &lt;- GET(url = query_url)\n      initial_parse &lt;- fromJSON(rawToChar(initial_response$content))\n      col_names &lt;- (initial_parse[1,])\n      colnames(initial_parse) &lt;- col_names\n      initial_parse &lt;- initial_parse[-1,]\n      initial_parse &lt;- as_tibble(initial_parse)\n      initial_parse_final &lt;- bind_rows(initial_parse,initial_parse_final)\n    }\n    return(initial_parse_final)\n}\n\n\n# Testing purposes/example\n# initial_parse &lt;- census_query(year = \"2011,2014\", \"State\", \"08\", \"AGEP,SEX\")\n\n\nNow we can create our final/main API query. This API query contains 4 parameters (year = “2022”, geography_level = “All”, geography_subset and get = “SEX,AGEP,PWGTP”, with their respective defaults) and takes in vector combined_vars. We create a strsplit for the get results, similarly to what we did for the years in the census_query results. When a user inputs variables, it will check and ensure those column names are valid. If they are then it will print, “Column X entered is valid” and if not then it will tell the user to try again. After that, initial_parse is reassigned and overwritten once it goes through each function (census_query, num_checker, time_checker, cat_checker) and checker (geo_checker, year_checker). Then will return a final tibble at the end.\n\n\n# Main API Query Function\n# Added combined_vars and for loop to validate and check inputted columns are valid\n\nmain_query &lt;- function(year = \"2022\", \n                       geography_level = \"All\", \n                       geography_subset,  \n                       get = \"SEX,AGEP,PWGTP\") {\n    combined_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWMNP\", \"PWGTP\", \"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\", \"JWAP\", \"JWDP\")\n    get_list &lt;- strsplit(get, \",\")\n    for (i in get_list[[1]]) {\n      if (i %in% combined_vars) {\n        cat(\"Column (\",i ,\") entered is valid.\")\n      }\n      else (\n        stop(\"Column (\",i,\") entered is not valid. Try again\")\n            )\n    }\n    initial_parse &lt;- census_query(year, geography_level, geography_subset, get)\n    initial_parse &lt;- num_checker(initial_parse)\n    initial_parse &lt;- cat_checker(initial_parse)\n    geo_checker(geography_level, geography_subset)\n    year_checker(year) \n    return(initial_parse)\n} \n\n# Testing purposes/example\n# test &lt;- main_query(\"2018,2015\", \"State\", \"08\", \"FER,JWAP,SEX,SCHL,GASP\")\n \n# All variable query\neverything &lt;- main_query(\"2022\", \"State\", \"08\", \"AGEP,GASP,GRPIP,JWMNP,PWGTP,FER,HHL,HISPEED,JWTRNS,SCH,SCHL,SEX,JWAP,JWDP\")\n\nColumn ( AGEP ) entered is valid.Column ( GASP ) entered is valid.Column ( GRPIP ) entered is valid.Column ( JWMNP ) entered is valid.Column ( PWGTP ) entered is valid.Column ( FER ) entered is valid.Column ( HHL ) entered is valid.Column ( HISPEED ) entered is valid.Column ( JWTRNS ) entered is valid.Column ( SCH ) entered is valid.Column ( SCHL ) entered is valid.Column ( SEX ) entered is valid.Column ( JWAP ) entered is valid.Column ( JWDP ) entered is valid.[1] \"PWGTP\"\n[1] \"GASP\"\n[1] \"AGEP\"\n[1] \"GRPIP\"\n[1] \"JWMNP\"\n[1] \"JWAP\"\n[1] \"JWDP\"\n[1] \"FER\"\n[1] \"HHL\"\n[1] \"HISPEED\"\n[1] \"JWTRNS\"\n[1] \"SCH\"\n[1] \"SCHL\"\n[1] \"SEX\"\n[1] \"Geography level is valid.\"\n\nprint(everything)\n\n# A tibble: 59,841 × 15\n   PWGTP  GASP FER    AGEP GRPIP JWMNP HHL   HISPEED JWTRNS SCH   SCHL  SEX   \n   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;   &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; \n 1    70     3 2        18     0     0 0     0       11     2     18    Female\n 2    41     3 0        35     0     0 0     0       0      1     14    Male  \n 3    35     3 0        40     0     0 0     0       0      1     13    Male  \n 4    30     3 2        20     0     0 0     0       0      2     19    Female\n 5     4     3 0        14     0     0 0     0       0      2     11    Male  \n 6    75     3 2        28     0     0 0     0       0      1     16    Female\n 7    22     3 0        47     0     0 0     0       0      1     16    Male  \n 8    36     3 0        28     0     0 0     0       0      1     16    Male  \n 9    59     3 0        77     0     0 0     0       0      1     16    Female\n10    11     3 0        20     0     2 0     0       10     1     18    Male  \n# ℹ 59,831 more rows\n# ℹ 3 more variables: JWAP &lt;chr&gt;, JWDP &lt;chr&gt;, state &lt;chr&gt;"
  },
  {
    "objectID": "Project1.html#part-ii-summarizing-the-data-and-plots",
    "href": "Project1.html#part-ii-summarizing-the-data-and-plots",
    "title": "Project1",
    "section": "",
    "text": "In this section we have created 2 functions “Summary” function takes the data from tibble and generate summary statistics (mean and standard deviation) for all numeric variables and counts for all categorical variables from the data frame. This function takes three arguments - class census, numeric variables to generate summary statistics and categorical variables.\n\n\n\n\n\ntest this"
  }
]