---
title: "Project1"
author: "Upendra Joshi & John Tuong"
  warning: false
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

# ST: 558, Project 1

### By Upendra Joshi & John Tuong

## Introduction

-   The Public Use Microdata Sample (PUMS) Census API (Application Programming Interface) is a collection of data files from the United States Census Bureau that provides access to data samples of the U.S. population and housing units. More specifically, these PUMS data sets cover the HUD's (U.S. Department of Housing and Urban Development) largest rental assistance programs (Public Housing, Section 8, etc). This data is compiled from responses to the American Community Surveys (ACS). The PUMS is comprised of two files: one for person records and the other for housing unit records. It includes geographic and household information including, but not limited to: family type, household income, race, gender, etc. The PUMS' data sets are valuable sources of information to policymakers and the researchers, as it can give some insight on how to better allocate resources and focus on helping those who need it the most.

-   By leveraging these data sets, we hope to not only grow our R skills, but to learn a little more about the world around us. For the first half, we'll be working on building functions, both helper and main functions, that will help us examine, check, process, manipulate, and build our main function to query PUMS' API. The second half of the project will build onto the first and delve into functions to that will summarize data and create visuals.

- First thing's first, with every R project, we install and load in the necessary packaaes to help create functions to do what need. 
```{r}
library(tidyverse)
library(httr)
library(jsonlite)
library(dplyr)
library(tidycensus)
```

-   Next, we are going to show how URL can interact with the PUMS' API. Typically we'd start with a more bare URL when building a URL from scratch (more on that later), but I ended choosing this one because it provided a more visually appealing output as an example. After setting up the URL and making a GET request to PUMS' API (a request sent to a server asking an API to provide a service/information), we'll take that raw data, and parse it into JSON. The initial_parse returns a tibble with the column names on the first row, so we extract those names and set them as the column names. Then we drop the first row and create a nice tibble to get a glimpse of what information the example_url contains (take a look below!). These are the steps to querying APIs. So in short, we assign a URL, formulate the API request, send it, allow time to handle the response, and process the data.

```{r}
example_url <- "https://api.census.gov/data/2022/acs/acs1/pums?get=SEX,PWGTP,MAR&SCHL=24"
initial_response <- GET(url = example_url)
initial_parse <- fromJSON(rawToChar(initial_response$content))
col_names <- (initial_parse[1,])
colnames(initial_parse) <- col_names
initial_parse <- initial_parse[-1,]
initial_parse <- as_tibble(initial_parse)
initial_parse
```

```{r}



# Time Stuff

temp <- httr::GET("https://api.census.gov/data/2022/acs/acs1/pums/variables/JWAP.json")

#turn it into a list
temp_list <- temp$content |> rawToChar() |>jsonlite::fromJSON()
#grab just the names of JWAP and their values
JWAP <- temp_list$values$item
#reorder just so it is clearer
JWAP_values <- JWAP[sort(names(JWAP))]



# Numeric variables
num_vars <- c("AGEP", "GASP", "GRPIP", "JWMNP", "PWGTP")

# Categorical variables
cat_vars <- c("FER", "HHL", "HISPEED", "JWTRNS", "SCH", "SCHL", "SEX")

# Time variables
time_vars <- c("JWAP", "JWDP")

# Geography variables
geo_vars <- c("All", "Region", "Division", "State")



# Year Checker
year_checker <- function(year) {
  if (year > 2022 | year < 2010) {
    print("Invalid year value. Please type in a number between 2010 and 2022")
  }
}


# Numeric Check
num_checker <- function(initial_parse, num_vars, time_vars) {
    col_names <- colnames(initial_parse) 
      for (name in col_names) {
         if (name %in% num_vars) {
            print(name)   
            initial_parse[[name]] <- as.numeric(initial_parse[[name]])
            
         }
        if (name %in% time_vars) {
            print(name)   
            initial_parse[[name]] <- as.POSIXct(initial_parse[[name]], format = "%H:%M")
            
        }
      }
    return(initial_parse)
}

# Below is to check our work
# initial_parse <- num_checker(initial_parse, num_vars, time_vars)


# Categorical variable check
cat_checker <- function(initial_parse, cat_vars) {
    col_names <- colnames(initial_parse) 
      for (name in col_names) {
         if (name %in% cat_vars) {
            print(name)   
            initial_parse[[name]] <- as.factor(initial_parse[[name]])
    }
      }
      return(initial_parse)
}

# Below is to check our work
# cat_checker(initial_parse, cat_vars)



#Geography Checker
geo_checker <- function(geography_level, geo_value, geo_vars) {
  if (geography_level %in% geo_vars) {
    print("Geography level is valid.") 
  }
  else {
    print("Geography level is not valid.")
  }
}


# Below is to check our work
# geo_checker("State", "08", geo_vars)


# Query the Census API
url <- "https://api.census.gov/data/"
initial_parse_final <- tibble()
census_query <- function(year, geography_level, geo_value, get, url) {
    year_list <- strsplit(year, ",")
    geo_meta <- paste0("&for=", geography_level,":",geo_value)
    if (geography_level == "All") {
      geo_meta <- ""
    }
    for (i in year_list[[1]]) {
      query_url <- paste0(url,i,"/acs/acs1/pums?","get=PWGTP,",get,geo_meta)
      initial_response <- GET(url = query_url)
      initial_parse <- fromJSON(rawToChar(initial_response$content))
      col_names <- (initial_parse[1,])
      colnames(initial_parse) <- col_names
      initial_parse <- initial_parse[-1,]
      initial_parse <- as_tibble(initial_parse)
      initial_parse_final <- bind_rows(initial_parse,initial_parse_final)
    }
    return(initial_parse_final)
}

# Below is to check our work
# initial_parse <- census_query(year = "2013", "All", "", "AGEP,SEX", url)



# Main API Query Function

main_query <- function(year = "2022", 
                       geography_level = "All", 
                       geo_value, 
                       get = "SEX,AGEP,PWGTP", 
                       url = url, 
                       num_vars = num_vars, 
                       cat_vars = cat_vars, 
                       time_vars = time_vars, 
                       geo_vars = geo_vars) {
    initial_parse <- census_query(year, geography_level, geo_value, get, url)
    initial_parse <- num_checker(initial_parse, num_vars, time_vars)
    initial_parse <- cat_checker(initial_parse, cat_vars)
    geo_checker(geography_level, geo_value, geo_vars)
    year_checker(year) 
    return(initial_parse)
} 
  

# Testing purposes/Example
test <- main_query("2015", "State", "06", "SCHL,GASP,PWGTP", url, num_vars, cat_vars, time_vars, geo_vars)





```

-   For the next step, we'll be creating a function to query the PUMS' API. This query will allow for the collection and preparation of data to analyze. Our function, api_query(), contains the following parameters: year = 2022 is defaulted (it's user defined; you can only choose from years 2010 to 2022), state will populate a random number, APEG/PWGTP are defaulted, and PWGTP will always be returned.

```{r}
# NOTES/DONT USE
api_query <- function(year = 2022, #Default
                      get = "AGEP,SEX", #Default
                      state =  "07") #Default
                       {
  if (year > 2022 | year < 2010) {
    print("Invalid year value. Please type in a number between 2010 and 2022")
  }
  main_url <- paste0("https://api.census.gov/data/",year,"/acs/acs1/pums?get=PWGTP,", get,"&for=state:",state)
  response <- GET(url = main_url) 
  parsed <- fromJSON(rawToChar(response$content))
  col_names1 <- (parsed[1,])
  colnames(parsed) <- col_names1
  parsed <- parsed[-1,]
  data_as_tibble <- as_tibble(parsed)
  print(colnames(data_as_tibble))
  data_as_tibble <- data_as_tibble %>% 
    slice(-1) %>%
    mutate(AGEP = as.integer(AGEP),
          PWGTP = as.integer(PWGTP)) # If too many, use across..*
return(data_as_tibble)
}
# NOTES/DONT USE
```

## PART I Obtaining the Data from PUMS API

### API Function

## PART II Summarizing the Data and Plots

### Summary Function

-   In this section we have created 2 functions "Summary" function takes the data from tibble and generate summary statistics (mean and standard deviation) for all numeric variables and counts for all categorical variables from the data frame. This function takes three arguments - class census, numeric variables to generate summary statistics and categorical variables.

### Plot Function

-   test this
